{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from glob import glob\n",
    "from itertools import zip_longest\n",
    "from typing import List\n",
    "\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import matplotlib\n",
    "import numba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyclesperanto_prototype as cle\n",
    "import xarray as xr\n",
    "from dask import delayed\n",
    "from dask_image.imread import imread\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from skimage import exposure, img_as_ubyte, measure, segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing xarray DataArray of images from file path globs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def clean_img_names(img_path_glob: str, img_name_regex: str):\n",
    "    \"\"\"clean_img_names takes a \"globbed\" string pattern, searches\n",
    "    for all files that match the pattern and extracts image names\n",
    "    from each file using a regular expression.\"\"\"\n",
    "    return [\n",
    "        re.findall(img_name_regex, os.path.basename(fn))[0]\n",
    "        for fn in sorted(glob(img_path_glob))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of clean_img_names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feed']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_img_names(\"docs/fe*\", r\"feed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert clean_img_names(\"docs/fe*\", r\"feed\") == [\"feed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def check_lists_identical(list_of_lists):\n",
    "    list_a = list_of_lists[0]\n",
    "\n",
    "    for l in list_of_lists:\n",
    "        if np.array_equal(l, list_a):\n",
    "            continue\n",
    "        else:\n",
    "            raise ValueError(\"not all lists have same length!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def img_path_to_xarr(\n",
    "    img_name_regex: str,\n",
    "    pixel_size: float = 0.275,\n",
    "    ch_name_for_first_dim: str = \"images\",\n",
    "    **channel_path_globs,\n",
    "):\n",
    "    imgs = list()\n",
    "    channels = list()\n",
    "    img_names = list()\n",
    "\n",
    "    for channel_name, img_path_glob in channel_path_globs.items():\n",
    "        channels.append(channel_name)\n",
    "        imgs.append(imread(img_path_glob))\n",
    "        img_names.append(clean_img_names(img_path_glob, img_name_regex))\n",
    "\n",
    "    check_lists_identical(img_names)\n",
    "    return xr.DataArray(\n",
    "        data=da.stack(imgs),\n",
    "        coords=[\n",
    "            channels,\n",
    "            img_names[0],\n",
    "            np.arange(0, imgs[0].shape[1] * pixel_size, pixel_size),\n",
    "            np.arange(0, imgs[0].shape[2] * pixel_size, pixel_size),\n",
    "        ],\n",
    "        dims=[ch_name_for_first_dim, \"img_name\", \"y\", \"x\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def last2dims(f):\n",
    "    def func(array):\n",
    "        return f(array[0, 0, ...])[None, None, ...]\n",
    "\n",
    "    return func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for regionprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def check_channels_input_suitable_and_return_channels(\n",
    "    channels, available_channels: list\n",
    "):\n",
    "    if channels is not None:\n",
    "        try:\n",
    "            channels + []\n",
    "            if not set(channels).issubset(available_channels):\n",
    "                raise ValueError(f\"{channels} not in {available_channels}\")\n",
    "        except ValueError:\n",
    "            raise\n",
    "        except TypeError:\n",
    "            raise TypeError(\"channels must be a list\")\n",
    "        except Exception as e:\n",
    "            raise\n",
    "    else:\n",
    "        channels = available_channels\n",
    "\n",
    "    return channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def extend_region_properties_list(extra_properties: list = None):\n",
    "    properties = [\"label\", \"area\", \"mean_intensity\", \"centroid\"]\n",
    "    if extra_properties is None:\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            properties = properties + extra_properties\n",
    "        except TypeError:\n",
    "            raise TypeError(\"extra_properties must be a list\")\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    return properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def add_scale_regionprops_table_area_measurements(df, pixel_size):\n",
    "    df_with_um2 = (df.filter(regex=r\"area\") * (pixel_size ** 2)).add_suffix(\"_um2\")\n",
    "    return pd.concat([df, df_with_um2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delayed\n",
    "def lazy_props(seg, img, seg_ch, img_ch, seg_name, img_name, properties, **kwargs):\n",
    "    df = pd.DataFrame(\n",
    "        measure.regionprops_table(seg, img, properties=properties, **kwargs)\n",
    "    )\n",
    "    df[\"seg_ch\"] = seg_ch\n",
    "    df[\"int_img_ch\"] = img_ch\n",
    "    df[\"seg_img\"] = seg_name\n",
    "    df[\"int_img\"] = img_name\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def reorder_df_to_put_ch_info_first(df):\n",
    "    first_cols = [\n",
    "        \"seg_ch\",\n",
    "        \"int_img_ch\",\n",
    "        \"seg_img\",\n",
    "        \"int_img\",\n",
    "    ]\n",
    "    first_cols.extend(df.columns)\n",
    "    first_cols = sorted(set(first_cols), key=first_cols.index)\n",
    "    return df[first_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def is_label_image(img):\n",
    "    return np.unique(img).shape[0] < 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def generate_random_cmap(num_of_colors=2000):\n",
    "    colors = np.random.rand(num_of_colors, 3)\n",
    "    colors[0, :] = 0\n",
    "    return matplotlib.colors.ListedColormap(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def what_cmap(img, img_cmap, label_cmap):\n",
    "    return label_cmap if is_label_image(img) else img_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def figure_rows_columns(total_fig_axes: int, rows=3):\n",
    "    return (np.ceil(total_fig_axes / rows).astype(int), rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def auto_figure_size(figure_shape):\n",
    "    return figure_shape[1] * 4, figure_shape[0] * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def plot_new_images(\n",
    "    images,\n",
    "    label_text,\n",
    "    label_letter=None,\n",
    "    figure_shape=None,\n",
    "    figure_size=None,\n",
    "    img_cmap=\"gray\",\n",
    "    label_cmap=None,\n",
    "    colorbar=False,\n",
    "    **kwargs,\n",
    "):\n",
    "    if figure_shape is None:\n",
    "        figure_shape = figure_rows_columns(len(images))\n",
    "        \n",
    "    if figure_size is None:\n",
    "        figure_size = auto_figure_size(figure_shape)\n",
    "        \n",
    "    fig, ax = plt.subplots(\n",
    "        nrows=figure_shape[0],\n",
    "        ncols=figure_shape[1],\n",
    "        figsize=figure_size,\n",
    "    )\n",
    "\n",
    "    if label_cmap is None:\n",
    "        label_cmap = generate_random_cmap()\n",
    "\n",
    "    if label_letter is None:\n",
    "        label_letter = string.ascii_lowercase[: len(label_text)]\n",
    "\n",
    "    for (img, ax, letter, text) in zip_longest(\n",
    "        images, ax.flatten(), label_letter, label_text\n",
    "    ):\n",
    "        if img is not None:\n",
    "            im = ax.imshow(img, cmap=what_cmap(img, img_cmap, label_cmap), **kwargs)\n",
    "            ax.set_title(f\"({letter}) {text}\")\n",
    "            ax.axis(\"off\")\n",
    "        else:\n",
    "            ax.set_axis_off()\n",
    "    if colorbar:\n",
    "        fig2, cax = plt.subplots(figsize=(figure_shape[1], 1))\n",
    "        plt.colorbar(im, cax=cax, orientation=\"horizontal\")\n",
    "        cax.set_title(\"number of neighbours\")\n",
    "        fig.axes.append(cax)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def RGB_image_from_CYX_img(red=None, green=None, blue=None, ref_ch=2, clims=(2, 98)):\n",
    "    RGB_image = list([red, green, blue])\n",
    "    for i in range(len(RGB_image)):\n",
    "        if RGB_image[i] is None:\n",
    "            RGB_image[i] = np.zeros(RGB_image[ref_ch].shape, dtype=np.uint8)\n",
    "        else:\n",
    "            RGB_image[i] = img_as_ubyte(RGB_image[i].copy())\n",
    "            RGB_image[i] = exposure.rescale_intensity(\n",
    "                RGB_image[i],\n",
    "                in_range=(\n",
    "                    np.percentile(RGB_image[i], clims[0]),\n",
    "                    np.percentile(RGB_image[i], clims[1]),\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    return np.stack(RGB_image, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def four_ch_CYX_img_to_three_ch_CYX_img(img):\n",
    "    img[0] = img[0] + img[3]\n",
    "    img[1] = img[1] + img[3]\n",
    "    img[2] = img[2] + img[3]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "## not currently in use\n",
    "def plot_threshold_imgs_side_by_side(img, thresh_img_dict, int_img_ch, seg_img_ch):\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=len(thresh_img_dict), ncols=2, figsize=(6, 3 * len(thresh_img_dict))\n",
    "    )\n",
    "    fig.suptitle(\" \")\n",
    "\n",
    "    for ax, (key, value) in zip(axes, thresh_img_dict.items()):\n",
    "        # separate long query across mulitple lines\n",
    "        key = re.sub(r\"&\", r\"\\n&\", key)\n",
    "\n",
    "        ax[0].imshow(value, cmap=\"gray\")\n",
    "        ax[0].set_title(f\"{seg_img_ch} labels that meet threshold:\\n{key}\")\n",
    "        ax[1].imshow(img, cmap=\"gray\")\n",
    "        ax[1].set_title(f\"{int_img_ch} channel image\")\n",
    "        ax[0].axis(\"off\")\n",
    "        ax[1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region overlap calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def region_overlap(\n",
    "    label_no, label_img_outer=None, label_img_inner=None, overlap_thresh=0.5\n",
    "):\n",
    "    overlap = label_img_outer[label_img_inner == label_no]\n",
    "    total_overlap_region = overlap.size\n",
    "    non_zero_count = np.count_nonzero(overlap)\n",
    "    ratio_non_zero = non_zero_count / total_overlap_region\n",
    "\n",
    "    if ratio_non_zero > overlap_thresh:\n",
    "        is_in = overlap[np.nonzero(overlap)]\n",
    "        is_in = mode(is_in)[0][0]\n",
    "\n",
    "    else:\n",
    "        is_in = 0\n",
    "\n",
    "    return is_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def calculate_overlap(img, num_of_segs=4, preallocate_value=1000):\n",
    "    num_dapi = np.unique(img[0])\n",
    "    l = np.zeros((num_of_segs - 1, preallocate_value), dtype=np.float64)\n",
    "    l[:] = np.nan\n",
    "    for label_no in num_dapi:\n",
    "        for i in range(l.shape[0]):\n",
    "            l[i, label_no] = region_overlap(label_no, img[i + 1, ...], img[0, ...])\n",
    "    return l[None, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def calc_allfilt_from_thresholds(thresholds: list, df):\n",
    "    filt_l = list()\n",
    "\n",
    "    # loop through and accumulate filter masks\n",
    "    for thresh in thresholds:\n",
    "        filt_l.append(df.eval(thresh))\n",
    "\n",
    "    # combine filter masks together\n",
    "    return (\n",
    "        pd.DataFrame(\n",
    "            np.stack(filt_l, axis=1),\n",
    "            index=pd.MultiIndex.from_frame(df[[\"int_img\", \"label\"]]),\n",
    "        )\n",
    "        .groupby([\"int_img\", \"label\"])\n",
    "        .any()\n",
    "        .all(axis=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def concat_list_of_thresholds_to_string(thresholds):\n",
    "    thresholds = \"\\n\\n\".join(thresholds)\n",
    "    return re.sub(r\"&\", r\"&\\n\", thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Touching cell calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def generate_touch_counting_image(g_img):\n",
    "    touch_matrix = cle.generate_touch_matrix(cle.push(g_img))\n",
    "    touch_matrix = cle.set_column(touch_matrix, 0, 0)\n",
    "    counts = cle.count_touching_neighbors(touch_matrix)\n",
    "    return cle.replace_intensities(g_img, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def adjusted_cell_touch_images(\n",
    "    total_neigh_counts, neg_neigh_neg, pos_neigh_pos, pos_binary_image\n",
    "):\n",
    "    neg_neigh_pos = (\n",
    "        total_neigh_counts - neg_neigh_neg - pos_neigh_pos\n",
    "    ) * pos_binary_image\n",
    "\n",
    "    pos_neigh_neg = (total_neigh_counts - neg_neigh_neg - pos_neigh_pos) * np.invert(\n",
    "        pos_binary_image\n",
    "    )\n",
    "\n",
    "    neg_neigh_counts = neg_neigh_neg + neg_neigh_pos\n",
    "\n",
    "    pos_neigh_counts = pos_neigh_pos + pos_neigh_neg\n",
    "\n",
    "    return neg_neigh_counts, pos_neigh_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delayed\n",
    "def calc_neighbours(lab_img, to_keep, calc_clones):\n",
    "    g_lab_img = cle.push(lab_img)\n",
    "\n",
    "    extended_lab_img = segmentation.clear_border(\n",
    "        cle.pull(cle.extend_labeling_via_voronoi(g_lab_img))\n",
    "    )\n",
    "\n",
    "    binary_filt = np.isin(extended_lab_img, to_keep)\n",
    "    filtered_extended_lab = binary_filt * extended_lab_img\n",
    "    opposite_filtered_extended_lab = np.invert(binary_filt) * extended_lab_img\n",
    "\n",
    "    g_filtered_extended_lab = cle.push(filtered_extended_lab)\n",
    "\n",
    "    total_neigh_counts = cle.pull(\n",
    "        generate_touch_counting_image(cle.push(extended_lab_img))\n",
    "    )\n",
    "    pos_neigh_pos = cle.pull(\n",
    "        generate_touch_counting_image(cle.push(filtered_extended_lab))\n",
    "    )\n",
    "    neg_neigh_neg = cle.pull(\n",
    "        generate_touch_counting_image(cle.push(opposite_filtered_extended_lab))\n",
    "    )\n",
    "\n",
    "    neg_neigh_counts, pos_neigh_counts = adjusted_cell_touch_images(\n",
    "        total_neigh_counts, neg_neigh_neg, pos_neigh_pos, binary_filt\n",
    "    )\n",
    "\n",
    "    stack = [\n",
    "        extended_lab_img,\n",
    "        opposite_filtered_extended_lab,\n",
    "        filtered_extended_lab,\n",
    "        total_neigh_counts,\n",
    "        neg_neigh_counts,\n",
    "        pos_neigh_counts,\n",
    "    ]\n",
    "\n",
    "    if calc_clones:\n",
    "        stack.insert(\n",
    "            3,\n",
    "            cle.pull(\n",
    "                cle.connected_components_labeling_box(\n",
    "                    cle.merge_touching_labels(g_filtered_extended_lab)\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    return np.stack(stack).astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_all_labeled_clones_unmerged_and_merged(\n",
    "    total_seg_labels, labels_to_keep: dict, calc_clones: bool\n",
    "):\n",
    "    img_list = list()\n",
    "    first_dim = 6 + int(calc_clones)\n",
    "    for key in total_seg_labels.coords[\"img_name\"].values:\n",
    "        try:\n",
    "            img_list.append(\n",
    "                da.from_delayed(\n",
    "                    calc_neighbours(\n",
    "                        total_seg_labels.loc[key, ...].data,\n",
    "                        labels_to_keep[key],\n",
    "                        calc_clones,\n",
    "                    ),\n",
    "                    shape=(first_dim,) + total_seg_labels.shape[1:],\n",
    "                    dtype=np.uint16,\n",
    "                )\n",
    "            )\n",
    "        # KeyError exception occurs when query did not yield any labels to keep.\n",
    "        # Therefore, append empty array for this key instead.\n",
    "        except KeyError:\n",
    "            img_list.append(\n",
    "                da.zeros(\n",
    "                    shape=(first_dim,) + total_seg_labels.shape[1:], dtype=np.uint16\n",
    "                )\n",
    "            )\n",
    "    return da.stack(img_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delayed\n",
    "@numba.njit()\n",
    "def determine_labels_across_other_images_using_centroids(\n",
    "    image_1, centroids, first_output_dim, second_output_dim\n",
    "):\n",
    "    pre_arr = np.zeros((first_output_dim, second_output_dim), dtype=np.float64)\n",
    "    pre_arr[:] = np.nan\n",
    "    for i in range(centroids.shape[0]):\n",
    "        pre_arr[:, i] = image_1[:, centroids[i, 0], centroids[i, 1]]\n",
    "    return pre_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def calculate_corresponding_labels(\n",
    "    labels, centroids_list, first_output_dim, second_output_dim\n",
    "):\n",
    "    if not labels.shape[1] == len(centroids_list):\n",
    "        raise ValueError(\"not the same numbers of imgs as centroid pairs!\")\n",
    "\n",
    "    img_list = list()\n",
    "    for i in range(labels.shape[1]):\n",
    "        img_list.append(\n",
    "            da.from_delayed(\n",
    "                determine_labels_across_other_images_using_centroids(\n",
    "                    labels[:, i], centroids_list[i], first_output_dim, second_output_dim\n",
    "                ),\n",
    "                shape=(first_output_dim, second_output_dim),\n",
    "                dtype=np.float64,\n",
    "            )\n",
    "        )\n",
    "    return da.stack(img_list, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Editing xarray dims and coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def update_1st_coord_and_dim_of_xarr(xarr, new_coord: list, new_dim: str):\n",
    "    updated_coords = [new_coord] + [coords.data for coords in xarr.coords.values()][1:]\n",
    "    updated_dims = (new_dim,) + xarr.dims[1:]\n",
    "    return dict(zip(updated_dims, updated_coords)), updated_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
